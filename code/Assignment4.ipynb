{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-c--lb7ck2i"
      },
      "source": [
        "First, connect to my own drive. This has the data.py file in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aOz9Y96qKNG",
        "outputId": "807582a8-a8ee-48de-fd98-3301ad7f54cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/My Drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNVLRopxcqdX"
      },
      "source": [
        "Import some libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcnLygUTrzYz"
      },
      "source": [
        "#libraries\n",
        "import plotly.graph_objects as go \n",
        "from plotly.subplots import make_subplots\n",
        "from plotly.offline import iplot,init_notebook_mode\n",
        "import torch #cpu only version\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch\n",
        "from copy import deepcopy\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nmdLTCxcsnC"
      },
      "source": [
        "Install extra dependency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHedJVdvRX5n",
        "outputId": "4c458f29-a707-4848-b77e-e591a7e1602a"
      },
      "source": [
        "!pip install wget\n",
        "from data import *"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwT445t5ta6Q"
      },
      "source": [
        "\n",
        "Loading in the imdb data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dyxzVXJtJje"
      },
      "source": [
        "(x_train, y_train), (x_val, y_val) , (i2w, w2i), numcls =  load_imdb(final = False, char = False)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pl6d6FhvKPd"
      },
      "source": [
        "Some statistics about the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Av1jKuntiQk",
        "outputId": "2ecbb1d8-9fac-48de-935e-78e3864ccac2"
      },
      "source": [
        "def batch_max(sequences: list): \n",
        "    \"\"\"\n",
        "    Determines the max length of the lists in the list.\n",
        "    \"\"\"\n",
        "    return max(len(sequence) for sequence in sequences)\n",
        "\n",
        "max_ = batch_max(x_train)\n",
        "print(max_) #2514"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WsujQDRvAAc"
      },
      "source": [
        "Code below adds '.start', '.end' and '.pad' to the batches. Each batch contains approximately 3,500 tokens. This is causing batches to be variable. Since the maximum number of tokens in one instance is 2514, the minimal number of tokens in a batch is 2514. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW2RO6FAuHNL"
      },
      "source": [
        "(x_train, y_train), (x_val, y_val) , (i2w, w2i), numcls =  load_imdb(final = False, char = False)\n",
        "MAXIMUM_TOKENS =  15000\n",
        "\n",
        "def add_start(sequence: list): sequence.insert(0, 1)\n",
        "def add_end(sequence: list): sequence.append(2)\n",
        "def delete_first(sequence: list): del sequence[0]\n",
        "def add_zero(sequence: list): sequence.append(0)\n",
        "\n",
        "def add_pad(sequence: list, padding: int):  \n",
        "    for _ in range(padding): sequence.append(0)\n",
        "\n",
        "def pre_process_sequences(sequences : list, targets : list):\n",
        "    batches, batch_targets = [],[]\n",
        "    number_of_sequences = len(sequences)\n",
        "    start = 0\n",
        "    for _ in range(number_of_sequences):\n",
        "        end =  start\n",
        "        number_of_tokens = 0\n",
        "        #determine batch size\n",
        "        while (number_of_tokens + len(sequences[end-1]) < (MAXIMUM_TOKENS )):\n",
        "            if end < number_of_sequences : number_of_tokens += len(sequences[end])\n",
        "            else: break\n",
        "            end += 1\n",
        "\n",
        "        #make batch\n",
        "        b, b_targets = sequences[start:end], targets[start:end]\n",
        "        \n",
        "        #add special tokens\n",
        "        max_seq_length = len(b[-1])\n",
        "        for sequence in b:\n",
        "            add_start(sequence)\n",
        "            add_end(sequence)\n",
        "            padding =  max_seq_length + 2 - len(sequence)\n",
        "            if padding > 0: add_pad(sequence, padding = padding )\n",
        "            #if len(sequence) != max_seq_length\n",
        "        b =  torch.tensor(b, dtype=torch.long)\n",
        "        b_targets =  torch.tensor(b_targets, dtype=torch.long)\n",
        "        \n",
        "\n",
        "        batches.append(b)\n",
        "        batch_targets.append(b_targets)\n",
        "\n",
        "        start = end\n",
        "        if end >= number_of_sequences: break\n",
        "\n",
        "    return batches, batch_targets"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2yS4InDxWR-"
      },
      "source": [
        "batches, batch_targets = pre_process_sequences(x_train, y_train)\n",
        "batches_val, batches_targets = pre_process_sequences(x_val, y_val)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEx6oz05y-6E"
      },
      "source": [
        "Quick check. Seems to be in order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZRsphRgyBLa",
        "outputId": "dd6b1483-21ac-4ec8-cb4d-87b1027496d6"
      },
      "source": [
        "print('Number of batches:', len(batches))\n",
        "print('Number of batches (targets):', len(batch_targets))\n",
        "print('')\n",
        "print('Length of first batch:', len(batches[0]))\n",
        "print('Length of first batch:', len(batch_targets[0]))\n",
        "print('')\n",
        "print('Length of last batch:', len(batches[-1]))\n",
        "print('Length of last batch:', len(batch_targets[-1]))\n",
        "print('')\n",
        "print('Example sentence: ', ' '.join([i2w[word] for word in list(batches[0][3])]))\n",
        "print('Shape of batch: ', batch_targets[-1].size())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of batches: 325\n",
            "Number of batches (targets): 325\n",
            "\n",
            "Length of first batch: 368\n",
            "Length of first batch: 368\n",
            "\n",
            "Length of last batch: 8\n",
            "Length of last batch: 8\n",
            "\n",
            "Example sentence:  .start long boring blasphemous never have i been so glad to see ending credits roll .end .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad .pad\n",
            "Shape of batch:  torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM2s9sNiz0LX"
      },
      "source": [
        "Batches have now variable size (and padding). One disadvantage is that it requires some RAM to have them all loaded in. On the other side, it is possible to easily shuffle the batches during training. The function below does that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyFGc9d7ywfH"
      },
      "source": [
        "from random import shuffle\n",
        "def shuffle_lists(list1: list, list2: list):\n",
        "  \"\"\"\n",
        "  Shuffels two lists in the same order.\n",
        "  In our case the two lists containing torch tensors (data and targets).\n",
        "  Based on: https://stackoverflow.com/questions/23289547/shuffle-two-list-at-once-with-same-order.\n",
        "  This function should be called upon each beginning, or end, of each epoch.\n",
        "  \"\"\"\n",
        "  list1, list2 =  deepcopy(list1), deepcopy(list2)\n",
        "  original = list(zip(list1, list2))\n",
        "  shuffle(original)\n",
        "  list1, list2 = zip(*original)\n",
        "  return list1, list2"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afSfDyMUeC5Z"
      },
      "source": [
        "Next, GPU for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9IXRGcpQ2i5"
      },
      "source": [
        "if torch.cuda.is_available(): device = torch.device(\"cuda\")\n",
        "else: device = torch.device(\"cpu\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "opHg8_O1a1hb",
        "outputId": "52081077-6956-45c9-db62-a4440f70d4f2"
      },
      "source": [
        "torch.version.cuda"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'10.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KFdC-b24lbO"
      },
      "source": [
        "Linear model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERWvTU_51vY2"
      },
      "source": [
        "vocab_size = len(i2w)\n",
        "class EmbedLin(nn.Module):\n",
        "    def __init__(self, emb_dim = 300, vocab_size = 20, hidden_size = 300, classes = 2 ): \n",
        "        super(EmbedLin, self).__init__()\n",
        "        self.emb_dim =  emb_dim\n",
        "        self.vocab_size =  vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.classes = classes\n",
        "\n",
        "        self.emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.fc1 = nn.Linear(self.emb_dim, self.hidden_size)\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.max(x, 1)[0]\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU-I_6kX4q97"
      },
      "source": [
        "Elman RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irr53SvH4p7j"
      },
      "source": [
        "class Elman(nn.Module):\n",
        "  def __init__ ( self , insize= 300 , outsize= 300 , hsize= 300 ):\n",
        "    super(). __init__ ()\n",
        "\n",
        "    self.lin1 = nn.Linear(insize + hsize, hsize)\n",
        "    self.lin2 = nn.Linear(hsize, outsize)\n",
        "\n",
        "  def forward( self , x, hidden= None):\n",
        "    b, t, e = x.size()\n",
        "\n",
        "    if hidden is None :\n",
        "      hidden = torch.zeros(b, e, dtype =torch.float)\n",
        "\n",
        "    outs = []\n",
        "    x = x.to(device)\n",
        "    hidden = hidden.to(device)\n",
        "\n",
        "    for i in range (t):\n",
        "\n",
        "      inp = torch.cat([x[:, i, :], hidden], dim = 1 )\n",
        "      hidden = torch.sigmoid(self.lin1(inp))\n",
        "      out = self.lin2(hidden)\n",
        "\n",
        "      outs.append(out[:, None , :])\n",
        "\n",
        "    return torch.cat(outs, dim = 1 ), hidden\n",
        "\n",
        "class ElmanRNN(nn.Module):\n",
        "    def __init__(self, emb_dim = 300, vocab_size = 20, \n",
        "                 hidden_size = 300, classes = 2 ): \n",
        "        super(ElmanRNN, self).__init__()\n",
        "        self.emb_dim =  emb_dim\n",
        "        self.vocab_size =  vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.classes = classes\n",
        "\n",
        "        self.emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.elman = Elman()\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.classes)\n",
        "\n",
        "    def forward(self, x, hidden = None):\n",
        "        x = self.emb(x)\n",
        "        x = self.elman(x, hidden)[0]\n",
        "        x = F.relu(x)\n",
        "        x = torch.max(x, 1)[0]\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJmrBk2C4u4b"
      },
      "source": [
        "RNN, LSTM, Bi-LSTM. Not the best implementation but it does the job.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0x4yvUEeLaV"
      },
      "source": [
        "class RecNet(nn.Module):\n",
        "    def __init__(self, emb_dim = 300, vocab_size = 20, \n",
        "                 hidden_size = 300, classes = 2, model = 'elman'): \n",
        "        super(RecNet, self).__init__()\n",
        "        self.model = model\n",
        "        self.emb_dim =  emb_dim\n",
        "        self.vocab_size =  vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.classes = classes\n",
        "\n",
        "        if self.model == 'elman':\n",
        "          self.emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "          self.unit = nn.RNN(self.emb_dim, self.hidden_size, nonlinearity='relu')\n",
        "          self.fc2 = nn.Linear(self.hidden_size, self.classes)\n",
        "        \n",
        "        if self.model == 'lstm':\n",
        "          self.emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "          self.unit = nn.LSTM(self.emb_dim, self.hidden_size)\n",
        "          self.fc2 = nn.Linear(self.hidden_size, self.classes)\n",
        "        \n",
        "        if self.model == 'bilstm':\n",
        "          self.emb = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "          self.unit = nn.LSTM(self.emb_dim, self.hidden_size, bidirectional = True )\n",
        "          self.fc2 = nn.Linear(self.hidden_size * 2, self.classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.model == 'elman':\n",
        "        x = self.emb(x)\n",
        "        x = self.unit(x)[0]\n",
        "        x = torch.max(x, 1)[0]\n",
        "        x = self.fc2(x)\n",
        "\n",
        "      if self.model == 'lstm':\n",
        "        x = self.emb(x)\n",
        "        x = F.relu(self.unit(x)[0])\n",
        "        x = torch.max(x, 1)[0]\n",
        "        x = self.fc2(x)\n",
        "\n",
        "      if self.model == 'bilstm':\n",
        "        x = self.emb(x)\n",
        "        x = F.relu(self.unit(x)[0])\n",
        "        x = torch.max(x, 1)[0]\n",
        "        x = self.fc2(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q16dpC1p4wpP"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4_pD5q_4qe7"
      },
      "source": [
        "def accuracy(net_, x:list, targets: list):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "      i = 0\n",
        "      for values, labels in zip(x, targets):\n",
        "        # print(len(values), len(labels),i)\n",
        "        values = values.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net_(values)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        i+=1\n",
        "    accuracy = correct/total\n",
        "    return accuracy\n",
        "\n",
        "def calculate_loss(net_,  x :list, targets: list):\n",
        "    losses = 0.0\n",
        "    for values, labels in zip(x, targets):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        values = values.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net_(values)\n",
        "        loss = criterion(outputs, labels)\n",
        "        losses += loss\n",
        "    return losses / len(x)\n",
        "        \n",
        "def train(net_, X_train, y_train, criterion, scheduler, \n",
        "          optimizer, X_val = None, y_val = None ,epochs = 5):\n",
        "    #lists for results\n",
        "    losses_train, losses_val = [],[]\n",
        "    accuracy_train, accuracy_val = [],[]\n",
        "    running_loss,accuracy_batch = [], []\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        print(\"Epoch: \", epoch)\n",
        "        epoch_loss = []\n",
        "        #print accuracies\n",
        "        acc= accuracy(net_, X_train, y_train)\n",
        "        accuracy_train.append(acc)\n",
        "        #shuffling lists (to have longer and shorter sequences random)\n",
        "        X_train, y_train = shuffle_lists(X_train, y_train)\n",
        "\n",
        "        if X_val is not None: #if not final run\n",
        "            acc_val = accuracy(net_, X_val, y_val)\n",
        "            accuracy_val.append(acc_val)\n",
        "\n",
        "        for inputs, labels in zip(X_train, y_train):\n",
        "            #inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # zero the parameter gradients\n",
        "            net_.zero_grad()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        " \n",
        "            outputs = net_(inputs)\n",
        "\n",
        "            #batch accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total = labels.size(0)\n",
        "            correct = (predicted == labels).sum().item()\n",
        "            accuracy_batch.append(correct/total)\n",
        "\n",
        "            #loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            epoch_loss.append(loss.detach().cpu().numpy())\n",
        "            loss.backward()\n",
        "            \n",
        "\n",
        "            #optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "        #scheduler step\n",
        "        scheduler.step()    \n",
        "        running_loss.append(np.mean(epoch_loss))\n",
        "        #final run has no validation set, so printing will be different\n",
        "        if X_val is not None:\n",
        "            print(\"Accuracy train: {} --- Accuracy validation: {} --- Mean running loss: {}\\n \".format(round(acc,2), round(acc_val,2), running_loss[-1]))\n",
        "        else: print(\"Accuracy train: {}\\n \".format(round(acc,2)))\n",
        "    \n",
        "    # evaluate last epoch\n",
        "    acc= accuracy(net_, X_train, y_train)\n",
        "    accuracy_train.append(acc)\n",
        "\n",
        "    if X_val is not None: #if not final run\n",
        "        acc_val = accuracy(net_, X_val, y_val)\n",
        "        accuracy_val.append(acc_val)\n",
        "    if X_val is not None:\n",
        "          print(\"Accuracy train: {} --- Accuracy validation: {} --- Mean running loss: {}\\n \".format(round(acc,2), round(acc_val,2), running_loss[-1]))\n",
        "    else: print(\"Accuracy train: {}\\n \".format(round(acc,2)))\n",
        "    print('Finished Training')\n",
        "\n",
        "    if X_val is not None:\n",
        "        return net_, accuracy_train, accuracy_val, running_loss, accuracy_batch\n",
        "\n",
        "    else: return net_, accuracy_train, running_loss, accuracy_batch"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1jejQLqeUdm"
      },
      "source": [
        "Running the different models below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHaR08vDI9L6",
        "outputId": "f7fca49d-8449-4f24-dc9e-b53640986d1c"
      },
      "source": [
        "criterion =   nn.CrossEntropyLoss()\n",
        "net = EmbedLin(vocab_size=vocab_size)\n",
        "net.cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95, last_epoch=-1, verbose=False)\n",
        "net, acc_train, acc_val, running_loss, accuracy_batch = train(net, batches, batch_targets, criterion, \n",
        "                                                              scheduler, optimizer, batches_val, batches_targets)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5 --- Accuracy validation: 0.5 --- Mean running loss: 0.6059263944625854\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.81 --- Accuracy validation: 0.78 --- Mean running loss: 0.44229763746261597\n",
            " \n",
            "Epoch:  2\n",
            "Accuracy train: 0.85 --- Accuracy validation: 0.8 --- Mean running loss: 0.36199748516082764\n",
            " \n",
            "Epoch:  3\n",
            "Accuracy train: 0.87 --- Accuracy validation: 0.83 --- Mean running loss: 0.31871864199638367\n",
            " \n",
            "Epoch:  4\n",
            "Accuracy train: 0.88 --- Accuracy validation: 0.84 --- Mean running loss: 0.29047954082489014\n",
            " \n",
            "Accuracy train: 0.89 --- Accuracy validation: 0.85 --- Mean running loss: 0.29047954082489014\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIzSnESLG8Cv",
        "outputId": "f474b65c-1f30-4e3c-83c2-369004b43224"
      },
      "source": [
        "net2 = ElmanRNN(vocab_size=vocab_size)\n",
        "net2.cuda()\n",
        "optimizer2 = optim.Adam(net2.parameters(), lr = 0.005)\n",
        "scheduler2 = optim.lr_scheduler.ExponentialLR(optimizer2, gamma=0.95, last_epoch=-1, verbose=False)\n",
        "net2, acc_train2, acc_val2, running_loss2, accuracy_batch2 = train(net2, batches, batch_targets, criterion, \n",
        "                                                              scheduler2, optimizer2, batches_val, batches_targets)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5 --- Accuracy validation: 0.5 --- Mean running loss: 0.7024572491645813\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.63 --- Accuracy validation: 0.62 --- Mean running loss: 0.601559042930603\n",
            " \n",
            "Epoch:  2\n",
            "Accuracy train: 0.72 --- Accuracy validation: 0.7 --- Mean running loss: 0.5346124172210693\n",
            " \n",
            "Epoch:  3\n",
            "Accuracy train: 0.76 --- Accuracy validation: 0.72 --- Mean running loss: 0.46462148427963257\n",
            " \n",
            "Epoch:  4\n",
            "Accuracy train: 0.82 --- Accuracy validation: 0.76 --- Mean running loss: 0.387845516204834\n",
            " \n",
            "Accuracy train: 0.84 --- Accuracy validation: 0.75 --- Mean running loss: 0.387845516204834\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJd3nGwPgeUp",
        "outputId": "be614afe-5a4b-4662-9f32-10e345e96a4b"
      },
      "source": [
        "net3 = RecNet(vocab_size=vocab_size, model = 'elman')\n",
        "net3.cuda()\n",
        "optimizer3 = optim.Adam(net3.parameters(), lr = 0.0005)\n",
        "scheduler3 = optim.lr_scheduler.ExponentialLR(optimizer3, gamma=0.999, last_epoch=-1, verbose=False)\n",
        "net3, acc_train3, acc_val3, running_loss3, accuracy_batch3 = train(net3, batches, batch_targets, criterion, \n",
        "                                                              scheduler3, optimizer3, batches_val, batches_targets)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5 --- Accuracy validation: 0.51 --- Mean running loss: 0.45167025923728943\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.9 --- Accuracy validation: 0.86 --- Mean running loss: 0.2534712255001068\n",
            " \n",
            "Epoch:  2\n",
            "Accuracy train: 0.92 --- Accuracy validation: 0.88 --- Mean running loss: 0.1831967830657959\n",
            " \n",
            "Epoch:  3\n",
            "Accuracy train: 0.96 --- Accuracy validation: 0.9 --- Mean running loss: 0.11715751141309738\n",
            " \n",
            "Epoch:  4\n",
            "Accuracy train: 0.96 --- Accuracy validation: 0.9 --- Mean running loss: 0.07012201100587845\n",
            " \n",
            "Accuracy train: 0.99 --- Accuracy validation: 0.91 --- Mean running loss: 0.07012201100587845\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63KgVYs7gvFA",
        "outputId": "4c7f8104-07c1-43be-ede4-8b5123e7feaf"
      },
      "source": [
        "net4 = RecNet(vocab_size=vocab_size, model = 'lstm')\n",
        "net4.cuda()\n",
        "optimizer4 = optim.Adam(net4.parameters(), lr = 0.0001)\n",
        "scheduler4 = optim.lr_scheduler.ExponentialLR(optimizer4, gamma=0.95, last_epoch=-1, verbose=False)\n",
        "net4, acc_train4, acc_val4, running_loss4, accuracy_batch4 = train(net4, batches, batch_targets, criterion, \n",
        "                                                              scheduler4, optimizer4, batches_val, batches_targets)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5 --- Accuracy validation: 0.5 --- Mean running loss: 0.6089031100273132\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.79 --- Accuracy validation: 0.71 --- Mean running loss: 0.5050760507583618\n",
            " \n",
            "Epoch:  2\n",
            "Accuracy train: 0.83 --- Accuracy validation: 0.73 --- Mean running loss: 0.44978103041648865\n",
            " \n",
            "Epoch:  3\n",
            "Accuracy train: 0.84 --- Accuracy validation: 0.78 --- Mean running loss: 0.40538644790649414\n",
            " \n",
            "Epoch:  4\n",
            "Accuracy train: 0.87 --- Accuracy validation: 0.75 --- Mean running loss: 0.36929625272750854\n",
            " \n",
            "Accuracy train: 0.89 --- Accuracy validation: 0.81 --- Mean running loss: 0.36929625272750854\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJCkGtNO8QC1",
        "outputId": "773886cf-fbbf-4d5d-9e1c-8523b4cfcc3a"
      },
      "source": [
        "net5 = RecNet(vocab_size=vocab_size, model = 'bilstm')\n",
        "net5.cuda()\n",
        "optimizer5 = optim.Adam(net5.parameters(), lr = 0.0001)\n",
        "scheduler5 = optim.lr_scheduler.ExponentialLR(optimizer5, gamma=0.95, last_epoch=-1, verbose=False)\n",
        "net5, acc_train5, acc_val5, running_loss5, accuracy_batch5 = train(net5, batches, batch_targets, criterion, \n",
        "                                                              scheduler5, optimizer5, batches_val, batches_targets)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5 --- Accuracy validation: 0.5 --- Mean running loss: 0.587306022644043\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.85 --- Accuracy validation: 0.86 --- Mean running loss: 0.43278372287750244\n",
            " \n",
            "Epoch:  2\n",
            "Accuracy train: 0.88 --- Accuracy validation: 0.86 --- Mean running loss: 0.3489980399608612\n",
            " \n",
            "Epoch:  3\n",
            "Accuracy train: 0.91 --- Accuracy validation: 0.87 --- Mean running loss: 0.289218008518219\n",
            " \n",
            "Epoch:  4\n",
            "Accuracy train: 0.91 --- Accuracy validation: 0.89 --- Mean running loss: 0.24656076729297638\n",
            " \n",
            "Accuracy train: 0.94 --- Accuracy validation: 0.86 --- Mean running loss: 0.24656076729297638\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tti4fOI2dsSE"
      },
      "source": [
        "All models got good scores. Next, I checked the number of parameters per model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3BaPFBCdrfU",
        "outputId": "d790e96e-d78f-4261-9ab5-097e2fd8d9c6"
      },
      "source": [
        "print(\"Model 1: \",[p.numel() for p in net.parameters() if p.requires_grad])\n",
        "print(\"Model 2: \",[p.numel() for p in net2.parameters() if p.requires_grad])\n",
        "print(\"Model 3: \", [p.numel() for p in net3.parameters() if p.requires_grad])\n",
        "print(\"Model 4: \", [p.numel() for p in net4.parameters() if p.requires_grad])\n",
        "print(\"Model 5: \", [p.numel() for p in net4.parameters() if p.requires_grad])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1:  [29829000, 90000, 300, 600, 2]\n",
            "Model 2:  [29829000, 180000, 300, 90000, 300, 600, 2]\n",
            "Model 3:  [29829000, 90000, 90000, 300, 300, 600, 2]\n",
            "Model 4:  [29829000, 360000, 360000, 1200, 1200, 600, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hDoN4Mn_dCV"
      },
      "source": [
        "Graphs the running loss (batches) and epoch accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "49qq7uqEhIay",
        "outputId": "fcb015ca-9f40-4f03-c9fe-3ab8bcfe0220"
      },
      "source": [
        "#graph\n",
        "# plotting different learning curves\n",
        "x = list(np.arange(0,6))\n",
        "x_loss = list(np.arange(1, 6))\n",
        "fig = make_subplots(1,3, horizontal_spacing=0.12, subplot_titles= (\"Validation Accuracy\", \"Training Accuracy\", \"Mean running Loss\"))\n",
        "#validation\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_val,\n",
        "                         name = \"Linear\",\n",
        "                        connectgaps = True, \n",
        "                        line_color = 'olive'),\n",
        "                        row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_val2,\n",
        "                         name = \"Elman (implemented)\",\n",
        "                        connectgaps = True,\n",
        "                        line_color = 'red'),\n",
        "                        row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_val3,\n",
        "                         name = \"Elman (PyTorch)\",\n",
        "                        connectgaps = True,\n",
        "                        line_color = 'green'),\n",
        "                        row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_val4,\n",
        "                         name = \"LSTM\",\n",
        "                        connectgaps = True,\n",
        "                        line_color = 'blue'),\n",
        "                        row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_val5,\n",
        "                         name = \"Bi-LSTM\",\n",
        "                        connectgaps = True,\n",
        "                        line_color = 'black'),\n",
        "                        row=1, col=1)\n",
        "#training\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_train,\n",
        "                         name = \"Linear\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'olive'),\n",
        "                        row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_train2,\n",
        "                         name = \"Elman (implemented)\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'red'),\n",
        "                        row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_train3,\n",
        "                           name = \"Elman (PyTorch)\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'green'),\n",
        "                        row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_train4,\n",
        "                        name = \"LSTM\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'blue'),\n",
        "                        row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x = x ,\n",
        "                         y = acc_train5,\n",
        "                        name = \"Bi-LSTM\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'black'),\n",
        "                        row=1, col=2)\n",
        "#batch\n",
        "fig.add_trace(go.Scatter(x = x_loss ,\n",
        "                         y = running_loss,\n",
        "                        name = \"Linear\",\n",
        "                        connectgaps = True,\n",
        "                         showlegend=False,\n",
        "                        line_color = 'olive'),\n",
        "                        row=1, col=3)\n",
        "fig.add_trace(go.Scatter(x = x_loss ,\n",
        "                         y = running_loss2,\n",
        "                         name = \"Elman (implemented)\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'red'),\n",
        "                        row=1, col=3)\n",
        "fig.add_trace(go.Scatter(x = x_loss ,\n",
        "                         y = running_loss3,\n",
        "                         name = \"Elman (PyTorch)\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'green'),\n",
        "                        row=1, col=3)\n",
        "fig.add_trace(go.Scatter(x = x_loss ,\n",
        "                         y = running_loss4,\n",
        "                         name = \"LSTM\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'blue'),\n",
        "                        row=1, col=3)\n",
        "fig.add_trace(go.Scatter(x = x_loss ,\n",
        "                         y = running_loss5,\n",
        "                         name = \"Bi-LSTM\",\n",
        "                        connectgaps = True,\n",
        "                        showlegend=False,\n",
        "                        line_color = 'black'),\n",
        "                        row=1, col=3)\n",
        "fig.update_xaxes(title_text = \"Epoch\", row = 1, col = 1)\n",
        "fig.update_yaxes(title_text = \"Accuracy\", range=[0.0, 1.0], row =1, col =1)\n",
        "\n",
        "fig.update_xaxes(title_text = \"Epoch\",row = 1, col = 2)\n",
        "fig.update_yaxes(title_text = \"Accuracy\", range=[0.0, 1.0],row =1, col =2)\n",
        "\n",
        "fig.update_xaxes(title_text = \"Epoch\" ,row = 1, col = 3)\n",
        "fig.update_yaxes(title_text = \"Mean Running Loss\",row =1, col =3)\n",
        "\n",
        "\n",
        "fig.update_xaxes(nticks = 6,row = 1, col = 3)\n",
        "fig.update_xaxes(nticks = 6,row = 1, col = 2)\n",
        "fig.update_xaxes(nticks = 6,row = 1, col = 1)\n",
        "fig.update_layout(\n",
        "    title = \"The validation/training accuracy and mean running loss on the IMDB data\",\n",
        "    title_x=0.5,\n",
        "    height=450, width=1200,\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=12,\n",
        "        color=\"black\"\n",
        "    ),\n",
        "    legend=dict(\n",
        "    orientation=\"h\",\n",
        "    yanchor=\"bottom\",\n",
        "    y=-0.45,\n",
        "    xanchor=\"center\",\n",
        "    x=0.5\n",
        ")\n",
        ")\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"cb75398e-c5ad-4154-ab33-1ba463e57d3b\" class=\"plotly-graph-div\" style=\"height:450px; width:1200px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"cb75398e-c5ad-4154-ab33-1ba463e57d3b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'cb75398e-c5ad-4154-ab33-1ba463e57d3b',\n",
              "                        [{\"connectgaps\": true, \"line\": {\"color\": \"olive\"}, \"name\": \"Linear\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x\", \"y\": [0.4952, 0.7838, 0.8044, 0.8318, 0.8424, 0.8518], \"yaxis\": \"y\"}, {\"connectgaps\": true, \"line\": {\"color\": \"red\"}, \"name\": \"Elman (implemented)\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x\", \"y\": [0.4952, 0.6244, 0.6986, 0.7156, 0.7562, 0.7524], \"yaxis\": \"y\"}, {\"connectgaps\": true, \"line\": {\"color\": \"green\"}, \"name\": \"Elman (PyTorch)\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x\", \"y\": [0.5078, 0.8614, 0.881, 0.8986, 0.9002, 0.9066], \"yaxis\": \"y\"}, {\"connectgaps\": true, \"line\": {\"color\": \"blue\"}, \"name\": \"LSTM\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x\", \"y\": [0.5048, 0.715, 0.7294, 0.7848, 0.7484, 0.8102], \"yaxis\": \"y\"}, {\"connectgaps\": true, \"line\": {\"color\": \"black\"}, \"name\": \"Bi-LSTM\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x\", \"y\": [0.5048, 0.8572, 0.8628, 0.8738, 0.885, 0.8626], \"yaxis\": \"y\"}, {\"connectgaps\": true, \"line\": {\"color\": \"olive\"}, \"name\": \"Linear\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x2\", \"y\": [0.5012, 0.81415, 0.85025, 0.8689, 0.88275, 0.8907], \"yaxis\": \"y2\"}, {\"connectgaps\": true, \"line\": {\"color\": \"red\"}, \"name\": \"Elman (implemented)\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x2\", \"y\": [0.5012, 0.62745, 0.7177, 0.7573, 0.8207, 0.8424], \"yaxis\": \"y2\"}, {\"connectgaps\": true, \"line\": {\"color\": \"green\"}, \"name\": \"Elman (PyTorch)\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x2\", \"y\": [0.49985, 0.89905, 0.91655, 0.9569, 0.9563, 0.98905], \"yaxis\": \"y2\"}, {\"connectgaps\": true, \"line\": {\"color\": \"blue\"}, \"name\": \"LSTM\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x2\", \"y\": [0.4988, 0.7884, 0.8269, 0.8438, 0.872, 0.8862], \"yaxis\": \"y2\"}, {\"connectgaps\": true, \"line\": {\"color\": \"black\"}, \"name\": \"Bi-LSTM\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5], \"xaxis\": \"x2\", \"y\": [0.4988, 0.85465, 0.88395, 0.9079, 0.9126, 0.93965], \"yaxis\": \"y2\"}, {\"connectgaps\": true, \"line\": {\"color\": \"olive\"}, \"name\": \"Linear\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x3\", \"y\": [0.6059263944625854, 0.44229763746261597, 0.36199748516082764, 0.31871864199638367, 0.29047954082489014], \"yaxis\": \"y3\"}, {\"connectgaps\": true, \"line\": {\"color\": \"red\"}, \"name\": \"Elman (implemented)\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x3\", \"y\": [0.7024572491645813, 0.601559042930603, 0.5346124172210693, 0.46462148427963257, 0.387845516204834], \"yaxis\": \"y3\"}, {\"connectgaps\": true, \"line\": {\"color\": \"green\"}, \"name\": \"Elman (PyTorch)\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x3\", \"y\": [0.45167025923728943, 0.2534712255001068, 0.1831967830657959, 0.11715751141309738, 0.07012201100587845], \"yaxis\": \"y3\"}, {\"connectgaps\": true, \"line\": {\"color\": \"blue\"}, \"name\": \"LSTM\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x3\", \"y\": [0.6089031100273132, 0.5050760507583618, 0.44978103041648865, 0.40538644790649414, 0.36929625272750854], \"yaxis\": \"y3\"}, {\"connectgaps\": true, \"line\": {\"color\": \"black\"}, \"name\": \"Bi-LSTM\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x3\", \"y\": [0.587306022644043, 0.43278372287750244, 0.3489980399608612, 0.289218008518219, 0.24656076729297638], \"yaxis\": \"y3\"}],\n",
              "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Validation Accuracy\", \"x\": 0.12666666666666668, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Training Accuracy\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Mean running Loss\", \"x\": 0.8733333333333333, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"font\": {\"color\": \"black\", \"family\": \"Courier New, monospace\", \"size\": 12}, \"height\": 450, \"legend\": {\"orientation\": \"h\", \"x\": 0.5, \"xanchor\": \"center\", \"y\": -0.45, \"yanchor\": \"bottom\"}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"The validation/training accuracy and mean running loss on the IMDB data\", \"x\": 0.5}, \"width\": 1200, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.25333333333333335], \"nticks\": 6, \"title\": {\"text\": \"Epoch\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.37333333333333335, 0.6266666666666667], \"nticks\": 6, \"title\": {\"text\": \"Epoch\"}}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.7466666666666667, 1.0], \"nticks\": 6, \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"range\": [0.0, 1.0], \"title\": {\"text\": \"Accuracy\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"range\": [0.0, 1.0], \"title\": {\"text\": \"Accuracy\"}}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Mean Running Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cb75398e-c5ad-4154-ab33-1ba463e57d3b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwsQIbxF_lXF"
      },
      "source": [
        "Next, the final runs. It can be seen above that the models overfit after the third epoch, therefore the final runs will be done with 2 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWsXEjtp_uc2"
      },
      "source": [
        "(x_train_full, y_train_full), (x_test, y_test) , (i2w, w2i), numcls =  load_imdb(final = True, char = False)\n",
        "batches_full, batch_targets_full = pre_process_sequences(x_train_full, y_train_full)\n",
        "batches_test, batches_targets_test = pre_process_sequences(x_test, y_test) # due to time i have not made a function that makes just pads to the same length"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQk0_APACExL"
      },
      "source": [
        "The full model is trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2EUp9IBCD2c",
        "outputId": "69dec9eb-9a4f-4674-cd52-31637ab43994"
      },
      "source": [
        "net_final_elman = RecNet(vocab_size=vocab_size, model = 'elman')\n",
        "net_final_elman.cuda()\n",
        "optimizer_final_elman = optim.Adam(net_final_elman.parameters(), lr = 0.0005)\n",
        "scheduler_final_elman = optim.lr_scheduler.ExponentialLR(optimizer_final_elman, gamma=0.999, last_epoch=-1, verbose=False)\n",
        "net_final_elman, acc_train_final_elman, running_loss_final_elman, accuracy_batch_final_elman = train(net_final_elman, batches_full, batch_targets_full, criterion, \n",
        "                                                              scheduler_final_elman, optimizer_final_elman, epochs=2)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.86\n",
            " \n",
            "Accuracy train: 0.94\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W_aXypuNUfp",
        "outputId": "addc38fe-b91d-4465-89d1-64e0177a8d86"
      },
      "source": [
        "net_final_lstm = RecNet(vocab_size=vocab_size, model = 'lstm')\n",
        "net_final_lstm.cuda()\n",
        "optimizer_final_lstm  = optim.Adam(net_final_lstm .parameters(), lr = 0.0001)\n",
        "scheduler_final_lstm  = optim.lr_scheduler.ExponentialLR(optimizer_final_lstm , gamma=0.95, last_epoch=-1, verbose=False)\n",
        "net_final_lstm , acc_train_final_lstm ,  running_loss_final_lstm , accuracy_batch_final_lstm  = train(net_final_lstm ,  batches_full, batch_targets_full,criterion, \n",
        "                                                              scheduler_final_lstm , optimizer_final_lstm  , epochs=2)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.8\n",
            " \n",
            "Accuracy train: 0.83\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIVWhfGcNUqb",
        "outputId": "b1e94319-4bc9-4744-ba97-846f858f9dde"
      },
      "source": [
        "net_final_bilstm = RecNet(vocab_size=vocab_size, model = 'bilstm')\n",
        "net_final_bilstm.cuda()\n",
        "optimizer_final_bilstm  = optim.Adam(net_final_bilstm .parameters(), lr = 0.0001)\n",
        "scheduler_final_bilstm  = optim.lr_scheduler.ExponentialLR(optimizer_final_bilstm , gamma=0.95, last_epoch=-1, verbose=False)\n",
        "net_final_bilstm , acc_train_final_bilstm , running_loss_final_bilstm , accuracy_batch_final_bilstm  = train(net_final_bilstm , batches_full, batch_targets_full, criterion, \n",
        "                                                              scheduler_final_bilstm , optimizer_final_bilstm  , epochs=2)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.83\n",
            " \n",
            "Accuracy train: 0.87\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_1EdieeNhEm",
        "outputId": "1d016483-4fb4-485b-d2bc-94800b9e1057"
      },
      "source": [
        "net_final_linear = EmbedLin(vocab_size=vocab_size)\n",
        "net_final_linear.cuda()\n",
        "optimizer_final_linear = optim.Adam(net_final_linear.parameters(), lr = 0.0001)\n",
        "scheduler_final_linear = optim.lr_scheduler.ExponentialLR(optimizer_final_linear, gamma=0.95, last_epoch=-1, verbose=False)\n",
        "net_final_linear, acc_train_final_linear,  running_loss_final_linear, accuracy_batch_final_linear = train(net_final_linear, batches_full, batch_targets_full, criterion, \n",
        "                                                              scheduler_final_linear, optimizer_final_linear, epochs=2)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Accuracy train: 0.5\n",
            " \n",
            "Epoch:  1\n",
            "Accuracy train: 0.82\n",
            " \n",
            "Accuracy train: 0.85\n",
            " \n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2564gRHnJ8W",
        "outputId": "6ed99448-7c3e-430d-b1a1-cea8a1ac3d42"
      },
      "source": [
        "print(\"Linear\")\n",
        "print(\"The training accuracy: \", accuracy(net_final_linear, batches_full, batch_targets_full))\n",
        "print(\"The test accuracy: \", accuracy(net_final_linear, batches_test, batches_targets_test))\n",
        "print(\"\")\n",
        "print(\"Elman\")\n",
        "print(\"The training accuracy: \", accuracy(net_final_elman, batches_full, batch_targets_full))\n",
        "print(\"The test accuracy: \", accuracy(net_final_elman, batches_test, batches_targets_test))\n",
        "print(\"\")\n",
        "print(\"LSTM\")\n",
        "print(\"The training accuracy: \", accuracy(net_final_lstm, batches_full, batch_targets_full))\n",
        "print(\"The test accuracy: \", accuracy(net_final_lstm, batches_test, batches_targets_test))\n",
        "print(\"\")\n",
        "print(\"Bi-LSTM\")\n",
        "print(\"The training accuracy: \", accuracy(net_final_bilstm, batches_full, batch_targets_full))\n",
        "print(\"The test accuracy: \", accuracy(net_final_bilstm, batches_test, batches_targets_test))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear\n",
            "The training accuracy:  0.8526\n",
            "The test accuracy:  0.84356\n",
            "\n",
            "Elman\n",
            "The training accuracy:  0.9378\n",
            "The test accuracy:  0.90908\n",
            "\n",
            "LSTM\n",
            "The training accuracy:  0.827\n",
            "The test accuracy:  0.82108\n",
            "\n",
            "Bi-LSTM\n",
            "The training accuracy:  0.87372\n",
            "The test accuracy:  0.86852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FeLcf8rpA4C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}